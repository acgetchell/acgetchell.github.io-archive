{"pages":[{"url":"http://adamgetchell.org/atom-vs-clion.html","text":"Today I decided to give CLion a try. I need all the help I can get. (I also should mention that JetBrains generously gives free CLion licenses to students, teachers, and non-commercial open source projects.) Atom is very nice, and I've been using it since 0.1 for everything from \\(\\LaTeX\\) ing papers to writing this blog to everyday coding. However, my latest travails involve heavy use of the debugger , and doing so with heavily templated code on the command line is not so nice. So I was lured in with the promise of a nice, graphical debugger in an honest IDE . After tinkering around with it for an hour or so, and trawling through the forums, I've managed to get CLion to look very close to my Atom setup, except for the different syntax highlighting colors. But I'll get used to that, or I can always customize the color scheme to Atom's material syntax if it really bothers me. Pros: Code completion is nice. Refactoring is wonderful. Also, CLion is smart enough to point out things you don't need, such as .gitignore items covered by other definitions. In general, CLion seems to have a lot of best practices baked right in. It's really nice to be working with a tool that understands the C++ constructs , instead of just doing some clever pattern matching. Cons: No option to use Ninja as my build tool. This increases build times perceptibly (but a hack exists). Inexplicably builds in some hidden directory instead of the output directory (but see the roadmap for 2016.2 ). The debugger skips right past my set breakpoints. Sadly, the last two are pretty much dealbreakers. I've submitted a support request, and I really think that CLion 2016.2 looks very promising. But as of now I'll still be writing/ coding in Atom. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); var location_protocol = (false) ? 'https' : document.location.protocol; if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:'; mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Programming","title":"Atom vs. CLion"},{"url":"http://adamgetchell.org/jerusalem-2014-15.html","text":"And again, it's been quite awhile. The big news is the welcome addition of Benjamin to our family. You can see him studying with me in my profile picture. He's an incredible ball of energy and joy, and there's nothing like having him around to remind one of the meaning of life. Aside from that, and with Benjamin's encouragement, I've been busy the past year getting serious about doing my research. My project was recently accepted by the Mozilla Science Lab , a really cool effort which aims to harness open-source software towards basic research. This is a part of a general movement, along with \"new\" trends such as Software Carpentry and Data Science (themselves based on practices and techniques from Software Engineering , Agile Development , and NoSQL to name just a few). However, as I type this I am sitting here at Hebrew University , in sunny (but chilly, at least by a Californian's standards) Jerusalem attending the 32nd Winter School in Theoretical Physics on 100 Years of General Relativity: From Theory to Experiment and Back . I'm having a blast getting my brain filled! I will post more about what I've learned later. (Benjamin is already quite the world traveler, handling planes, trains, and sightseeing with aplomb.) Also, I've migrated from Octopress to Pelican, as others have done , for similar reasons. This post was very helpful in doing the conversion, especially the Blogger support added into pelican-import.py. This post helped with the GitHub pages support. Shalom and Happy New Year!","tags":"Physics","title":"Jerusalem 2014-15"},{"url":"http://adamgetchell.org/iterations.html","text":"It's been quite awhile since the last post, with lots of changes. I've: Converted to MacOS Changed my research codebase to C++ Migrated this blog from Blogger to Octopress Started on the path towards #prismbreak Gotten my blue belt in BJJ I'll say a little about each of these in turn. MacOS++ First, for scientific research MacOS < (Windows)++. I've tried both, I simply get more done in MacOS. Mainly, it's because there's generations of Unix tools I can still use in an honest bash shell. Homesick is simply lovely for managing your dotfiles, and bash-it is another awesome shell configuration management tool. I pretty much live in GitHub for anything public (research papers and code, presentations, work projects, and this blog) and with tools like Homebrew I can restore my development environment and files on any Mac I care to just by running a shell script. Second, any large complex pieces of software that I find worth purchasing such as Mathematica, Maple, Office, MindNode Pro, Parallels, SublimeText , or 1Password already runs fine on MacOS. As do myriads of other useful free or open source tools such as (let me look at my Dock) Chrome , Tor , DashDoc , GitHub , LightTable , EverNote , Zotero , Anki , and TrueCrypt . And then there's the software Apple bundles such as XCode, iTunes, iMessage, iWork, iMovie, and Garage band. Let's not forget that any non-console games I care about work great on Battle.Net or Steam . Or that the AppStore keeps paid apps in the cloud, and Homebrew/Homesick keeps the rest. Finally, if there are any Windows tools I absolutely have to have such as Visual Studio or modern versions of Outlook, Parallels works dandy. Now, putting on my IT hat for a moment, if you are in a corporate environment and don't care one whit about the command line, then Windows is the best for you. Or rather, you're probably indifferent (although you may want teh shiny ), but for your tech staff, Windows machines can be managed by the thousands with relative ease. Microsoft actually supports doing so in an efficient business fashion. Apple simply doesn't care about the enterprise space, and Google's toolkit doesn't quite fill in the gaps (although I am sure that Puppet masters will disagree with me). Also, if you live in Azure or Visual Studio or like the Surface hardware (and they are interesting) Windows has got it going (although some of us just buy Macs and load Windows, because the hardware is still shiny ). It goes without saying that if you're one of those folks that love rolling your own OS and hardware, Linux is for you. Most of us, I suspect, simply need to get things done. Hence the resurgence in MacOS share. C++ Some of you may remember that I'm working on quantum gravity . Now it turns out that for the kinds of things I want to do — construct simplicial manifolds by the thousands and manipulate their geometry to insert masses and other objects; then read off the various attributes of these spacetimes and the objects therein — I am going very far down a very deep rabbit hole named computational geometry . But lo, there was light and illumination in the dark tunnels of my madness, and its name is CGAL . And CGAL is written in C++ . (Oh, sure, there are Python bindings too. But they don't cover everything, and I haven't tested all of their functions.) But now that I'm down one rabbit hole, I may as well continue, and I've found much to my surprise I am enjoying re-learning and using C++. Luckily for me, the C++11 standard is here, and C++ really does feel like another language. CGAL makes fundamental use of generic programming, and the toolchain has gotten better too. With CGAL , C++, CMake , Doxygen and friends I am literate-ly test-kinda-driven developing my way for great good. Clojure and Lisp are still lovely. But I can generate 5 million simplex complexes in 10-50 seconds on just my laptop, and if there ever was a need for speed and parallelization I have it. (Ah, julia , you are a lovely language, Y U No compile on MacOS?) And maybe someday we'll have Quantum Gravity on your Desktop courtesy of BOINC . Octopress++ I moved from Blogger to Octopress for a number of reasons. Octopress is open source, works using git, and works well on GitHub. There are a ton of plug-ins and it's easy to write your own. I want to reclaim my network identity , and a platform that I can regenerate anyplace with just a git pull Mirroring the move to C++, this blog is written very infrequently but read, well more often than it is written. So the overhead of a database and a dynamic site is not worth it. Did I mention it works in git and GitHub? I live there these days. And the bash-it git aliases rock! rake preview rake generate rake deploy then gall gca gpo source is a lovely workflow. Lot's of resources to get going . Prismbreak++ We all kinda knew it . The internet is a vast info-trawl for almost anything, but especially all the private info people are trading away for services . Getting your own independent network identity is just the first step , but there are many, many others (such as using TrueCrypt for any cloud file storage on any files you care to keep private). There are also quite a few inconviences; after all there's a reason folks use the privacy-invading \" free \" services, and no I don't want Linux for my primary laptop. I'll (possibly) have more to say on this later. (If you are going to pick an operating system for privacy, the best choice is OpenBSD .) Martial Arts++ I've been practicing martial arts of various types for quite awhile now. I'm fairly highly ranked in a few. But the empirical evidence is in, and it is this: To fight effectively, you need awareness, strength, quickness, toughness, calmness, cardio, and a whole host of attributes often listed on RPG sheets. To which skill in striking, grappling, and on the ground are musts. I love Taekwondo and it's spin kicks, but I am not deluding myself. You simply don't learn to deal with most other forms of striking. You will have beautiful kicks, but someone with a few months of boxing will punch you in the face quite easily. And of course, any type of grappler that closes the distance (or, anytime you miss) will grab hold of you to your detriment. I learned Judo and love the throws, but I'd rate it below Wrestling and Sambo in effectiveness. Primarily due to the new rules changes which forbid wrestling-style double and single leg takedowns. And on the ground, of course, Brazilian Jiu-Jitsu is king. All of these statements are pretty easily tested. You can personally test it by going to boxing clubs, wrestling workouts, and BJJ gyms and see how you fare in these areas. Or you can just watch UFC and see professionals do the same. And if you object that all of these places have rules, and aren't a real fight: please tell me why you think various dirty tricks will win the day for you, especially when you're in an inferior position where your opponent can do the same back to you (but 10x worse). I teach Hapkido at the university, and I've always enjoyed that Hapkidoja did learn techniques in all of these areas. I competed in Taekwondo and Judo, and Hapkido synthesized them all together. It was good for practical self-defense. I try to teach it as such. (Yes, martial arts with sporting equivalents are superior. Nothing beats realistic practice.) But times change and things develop, and it's time to adapt and learn what works. And my BJJ academy , professor , and jiu-jitsu family rock! Also, competing in BJJ is scary fun!","tags":"misc","title":"Iterations"},{"url":"http://adamgetchell.org/general-relativity-flash-cards-using.html","text":"Anki is a neat spaced repetition system that allows you to maximize memorization efficiency, or something like that. Interestingly, I came across it on the Clojure group , and there are already decks available for learning Clojure . It accepts LaTeX, so I've decided to make a flash-deck of some handy formulas that pop up in General Relativity, because there's enough to learn without forgetting! (Also, it's handy to have LaTeX snippets someplace semi-permanent.) Bianchi identity: $$\\nabla_{[\\lambda}R_{\\rho\\sigma]\\mu\\nu}=0$$ Christoffel symbol: $$\\Gamma_{\\mu\\nu}&#94;{\\lambda}=\\frac{1}{2}g&#94;{\\lambda\\sigma}\\left(\\partial_{\\mu}g_{\\nu\\sigma}+\\partial_{\\nu}g_{\\sigma\\mu}-\\partial_{\\sigma}g_{\\mu\\nu}\\right)$$ Covariant derivative of a 1-form: $$\\nabla_{\\mu}\\omega_{\\nu}=\\partial_{\\mu}\\omega_{\\nu}-\\Gamma_{\\mu\\nu}&#94;{\\lambda}\\omega_{\\lambda}$$ Covariant derivative of a vector: $$\\nabla_{\\mu}V&#94;{\\nu}=\\partial_{\\mu}V&#94;{\\nu}+\\Gamma_{\\mu\\lambda}&#94;{\\nu}V&#94;{\\lambda}$$ Covariant form of Maxwell's equations: $$\\partial_{\\mu}F&#94;{\\nu\\mu}=J&#94;{\\nu}$$ $$\\partial_{[\\mu}F_{\\nu\\lambda]}=0$$ for $$J&#94;{\\nu}=\\left(\\rho,J&#94;{x},J&#94;{y},J&#94;{z}\\right)$$ and $$F_{\\mu\\nu}=\\left( \\begin{array}{cccc} 0 & -E_{1} & -E_{2} & -E_{3} \\\\ E_{1} & 0 & B_{3} & -B_{2} \\\\ E_{2} & -B_{3} & 0 & B_{1} \\\\ E_{3} & B_{2} & -B_{1} & 0 \\\\ \\end{array} \\right)$$ Riemann tensor: $$R_{\\sigma\\mu\\nu}&#94;{\\rho}=\\partial_{\\mu}\\Gamma_{\\nu\\sigma}&#94;{\\rho}-\\partial_{\\nu}\\Gamma_{\\mu\\sigma}&#94;{\\rho}+\\Gamma_{\\mu\\lambda}&#94;{\\rho}\\Gamma_{\\nu\\sigma}&#94;{\\lambda}-\\Gamma_{\\nu\\lambda}&#94;{\\rho}\\Gamma_{\\mu\\sigma}&#94;{\\lambda}$$ Properties of the Riemann tensor: $$R_{\\rho\\sigma\\mu\\nu}=-R_{\\sigma\\rho\\mu\\nu}$$ $$R_{\\rho\\sigma\\mu\\nu}=-R_{\\sigma\\rho\\nu\\mu}$$ $$R_{\\rho\\sigma\\mu\\nu}=R_{\\mu\\nu\\rho\\sigma}$$ $$R_{\\rho[\\sigma\\mu\\nu]}=0$$ Ricci tensor: $$R_{\\mu\\nu}=R_{\\mu\\lambda\\nu}&#94;{\\lambda}$$ Ricci scalar: $$R=R_{\\mu}&#94;{\\mu}=g&#94;{\\mu\\nu}R_{\\mu\\nu}$$ Einstein tensor: $$G_{\\mu\\nu}=R_{\\mu\\nu}-\\frac{1}{2}Rg_{\\mu\\nu}$$ Formulae from Sean Carroll's Spacetime and Geometry: An Introduction to General Relativity Anki synchronizes with DropBox, but it's a bit involved . When I get my deck synchronized and uploaded, I will post a link to it. Update: https://ankiweb.net/shared/info/1777635479 if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); var location_protocol = (false) ? 'https' : document.location.protocol; if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:'; mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Physics","title":"General Relativity flash-cards using Anki"},{"url":"http://adamgetchell.org/feynman-diagrams-in-latex.html","text":"Sometimes you need Feynman diagrams in papers. It turns out there are quite a few ways to get there, but the handiest is FeynMP. I'm using, in particular, MikTeX and TeXMaker, but something like this should work for other setups. Here are the steps: First, get the feynmf package from your package manager. Next, add the following to your \\(\\LaTeX\\) preamble: I know the package name says feynmp ; if you use that, you'll have a lot more errors. The feynmp package is nicer, and included when you install feynmf. [gist:id=3595449,file=feynmp-preamble.tex] Now, let's say you want to add a diagram for Compton scattering (the point of the whole exercise). I suggest wrapping it in a \\(\\LaTeX\\) figure for convenience; doing so will lead to something like this: Note the name of the file is compton. In your \\(\\LaTeX\\) working directory, there will be a file called compton.mp. You need to run the mpost command on it, like so: This generates compton.1. Now, compile your \\(\\LaTeX\\) (are you getting tired of the cute capitalization yet?) file again, and your diagram will appear! Note that you'll have to do this anytime you edit the figure (e.g. add labels, etc.) But if you think this is a pain, try the alternatives! Here's a post that set me on the track: http://physical-thought.blogspot.com/2008/08/feynmf-feynman-diagrams-in-latex.html Here's the details on getting your preamble correct: http://tex.stackexchange.com/questions/20241/how-to-use-kile-with-feynmf-or-feynmp Here's a quick tutorial on using feyMP: http://suppiya.files.wordpress.com/2008/02/fmfsamples.pdf Here's a more in-depth tutorial by Thorsten Ohl, the author of feynMP/feynMF: http://xml.web.cern.ch/ XML /textproc/feynmf.html Here's a quicker tutorial by Thorsten Ohl, https://docs.google.com/viewer?url=http://www-zeus.desy.de/~kind/latex/feynmf/fmfcnl3.ps&pli=1 And here's the actual manual: http://www.pd.infn.it/TeX/doc/latex/feynmf/manual.pdf Also, while we're on the topic, this site had a lot of invaluable tips for formatting math symbols: http://www.math.uiuc.edu/~hildebr/tex/displays.html I hope this shortens the learning curve for someone else! If you have any feedback or corrections, send notes or pull requests to the gists. Happy \\(\\LaTeX\\) -ing! if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); var location_protocol = (false) ? 'https' : document.location.protocol; if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:'; mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Physics","title":"Feynman diagrams in LaTeX"},{"url":"http://adamgetchell.org/can-ligo-detect-graviton.html","text":"A lecture given 10/27/08 by Professor Freeman Dyson of the Institute of Advanced Studies at Princeton, in honor of the 100th anniversary of the founding of the University of California, Davis. $$E=\\left(\\frac{c&#94;{2}}{32\\pi G}\\right)\\omega&#94;{2}f&#94;{2}$$ is the energy per gravity wave, where f is the dimensionless amplitude/strain. $$E_{s}=\\frac{\\hbar\\omega&#94;{4}}{c&#94;{3}}$$ is the energy per graviton, taken from \\(\\hbar\\omega\\) energy times \\(\\frac{\\omega&#94;3}{c&#94;3}\\) density $$f=\\left(32\\pi\\right)&#94;{\\frac{1}{2}}\\left(L_{p}\\frac{\\omega}{c}\\right)$$ is the strain per graviton. $$L_{p}=\\left(\\frac{G\\hbar}{c&#94;{3}}\\right)&#94;{\\frac{1}{2}}=1.4\\times10&#94;{-33}cm$$ $$\\delta=\\left(32\\pi\\right)&#94;{\\frac{1}{2}}L_{p}$$ Gives the linear displacement per graviton. Note that spherical objects can't radiate gravitational waves, and that binary stars produce kilohertz gravity waves. LIGO 's threshold is therefore \\(10&#94;{37}\\) gravitons. $$M\\delta&#94;{2}\\geq\\hbar T$$ is the uncertainty in position and velocity. $$D\\leq\\left(\\frac{GM}{c&#94;{2}}\\right)$$ (from combining previous two equations) $$\\delta&#94;{2}\\geq\\frac{\\hbar D}{M_{s}}$$ $$\\frac{GM}{c&#94;{2}}\\geq\\left(\\frac{c}{s}D\\right)>D$$ Which exceeds the Schwarzschild radius, so impossible. Then the Bohr-Rosenfeld argument is: $$\\Delta E\\_{x}(1)\\Delta E_{x}(2)\\approx\\hbar\\left|A(1,2)-A(2,1)\\right|$$ where A(2,1) is the field from dipole 2 at location 1. The detector is described by: $$D_{ab}=m\\int\\Psi_{b}&#94;{*}xy\\Psi_{a}d\\tau$$ where a is the initial state, b is the final state, and m is the detector mass. $$\\sigma(\\omega)=\\left(4\\pi&#94;{2}G\\frac{\\omega&#94;{3}}{c&#94;{3}}\\right)\\sum_{b}\\left|D_{ab}\\right|&#94;{2}\\delta(E_{b}-E_{a}-\\hbar\\omega)$$ $$S_{a}=\\int\\sigma(\\omega)\\frac{d\\omega}{\\omega}$$ is the logarithmic average taken over the graviton cross section. $$S_{a}=4\\pi&#94;{2}L_{p}&#94;{2}Q$$ Now consider the gravitophotoelectric effect, where the graviton removes an electron. $$Q=\\int\\left|\\left(x\\frac{\\partial}{\\partial y}+y\\frac{\\partial}{\\partial x}\\right)\\Psi_{a}\\right|&#94;{2}d\\tau$$ $$Q=\\frac{\\int\\bar{r}&#94;{4}\\left[f'(r)\\right]&#94;{2}d\\bar{r}}{\\int r&#94;{2}\\left[f(r)\\right]&#94;{2}dr}$$ $$\\int r&#94;{4}\\left[f'+\\left(\\frac{3}{2}r\\right)f\\right]&#94;{2}dr>0$$ $$Q>\\frac{3}{4}$$ $$f(r)=r&#94;{-n}e&#94;{-\\frac{r}{R}}$$ $$Q=1-\\frac{n}{6}$$ $$4\\pi&#94;{2}L_{p}&#94;{2}=4\\pi&#94;{2}G\\frac{\\hbar}{c&#94;{3}}=8\\times10&#94;{-65}cm&#94;{2}$$ This means that if you take a detector the mass of the Earth, squash it into a large flat sheet, and run it for the lifetime of the universe, you'll detect 4 gravitons. From the Sun, there are \\(10&#94;{8}\\) W of gravitons and \\(10&#94;{25}\\) W of neutrinos, and we can detect gravitons about \\(10&#94;{-35}\\) less than neutrinos. Special thanks to MathJAX and this post on how to use MathJax in Blogger ! N.B. There's a good followup post on Cosmic Variance , along with an earlier entry giving some good background information. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); var location_protocol = (false) ? 'https' : document.location.protocol; if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:'; mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Physics","title":"Can LIGO detect a graviton?"},{"url":"http://adamgetchell.org/hapkido-practicum-fall-2009_29.html","text":"[Physical Education Program, UC Davis](http://pe.ucdavis.edu/Site/Welcome.html \"Physical Education Program, UC Davis\") Hapkido Practicum Fall Quarter, 2009 Instructor: [Adam Getchell](mailto:acgetchell@ucdavis.edu \"Adam Getchell\") Disclaimer: Techniques shown here are meant for informative/illustrative purposes. Just because I provide a link here, does necessarily mean I fully agree with all of the content shown. It does mean I think there is value in some of what is being demonstrated. As with all endeavors, a component of critical thinking is necessary. If something shown here works and makes sense to you, great! Practice diligently. If you don't understand or agree with something here, think about it, ask questions, form your own conclusions, and adjust your training accordingly. Martial Arts is an individual affair, albeit one with a common set of core principles derived from physics, anatomy, psychology, and other quantifiable discliplines. In a time of crisis you do not necessarily have time to think! Neither should you lose your wits about you. One of the best ways to avoid this is to know, in advance, what you are prepared to do, and commit to doing so. If (or when) the moment comes, you have a basis for action. 9.28.09 Discussion: Syllabus Warmups: Running, circling, burpees , cartwheels , gymnastics forward roll Techniques: Forward roll , footwork , elbow strikes Further updates can be found at: http://docs.google.com/View?id=dckp3cwx_62csk8r4gk","tags":"misc","title":"Hapkido Practicum Fall 2009"},{"url":"http://adamgetchell.org/lisp-conversion.html","text":"A few months and a lot of Lisp later, I find myself convinced/converted … … To Clojure . Rajesh, you were right! As far as language ~~snobbery~~ coolness, it has a bunch of features I like such as: A REPL for fast development Functional programming with immutable values which makes it easy to reason about concurrency Concurrent programming via software transactional memory A Lisp-1 dialect OOP benefits without OOP using runtime polymorphism Lots of modern libraries by being hosted on the JVM A vibrant community (my F# groups , by contrast, have had barely 2 messages in the past month) To get an idea of what I mean, here's an anonymous function to find the odd numbers in a (lazy) sequence (which could be a list, vector, or hash map): This idea of lazy sequences is powerful, because you can do things like get the 10,001st prime number without blowing the stack: You can just see the number-crunchy goodness, mixed in with Lispy functional precision. As far as practicality, there is simply too much awesome stuff. The language itself is available on GitHub It has nice documentation to get you started quickly There are great learning resources: 4Clojure clojure-koans Nice examples of algorithms such as Quicksort using Clojure Easy translation from Practical Common Lisp A freely available killer IDE supporting Clojure with project building and GitHub support Simple to complex web application support to EC2 , Heroku , Google App Engine and others You can easily do TDD (test driven development), which is really handy if, say, you've got a bunch of math functions that you want to be sure are correct when you port/rewrite code. Here's a screenshot of IntelliJ with a typical Leiningen project open: [![](http://4.bp.blogspot.com/-M-dYvAMiipM/TtfPdohU_mI/AAAAAAAA_vE/NeiVEH5OKHs/s640/idea-lein.png)](http://4.bp.blogspot.com/-M-dYvAMiipM/TtfPdohU_mI/AAAAAAAA_vE/NeiVEH5OKHs/s1600/idea-lein.png) You can see the typical Leiningen project layout, with /src and /test folders and subfolders. First, we'll write a ~~function~~ test for a function we want which sums over all values in a given sequence: The test is in C:\\Projects\\ CDT \\Newton\\test\\Newton.test\\core.clj, and the :use [Newton.utilities] tells it to look in the file C:\\Projects\\ CDT \\Newton\\src\\Newton\\utilities.clj for our function. Note the use of metadata \\&#94;{:utilities true} to mark this as a utilities test, which we'll use later for organization. Our test checks that our to-be-defined sum test sums correctly over both a list and a vector. Now here's the contents of C:\\Projects\\ CDT \\Newton\\src\\Newton\\utilities.clj: Finally, Leiningen allows us to choose test selectors so that we can specify which tests we want to run via project.clj: Now by running lein at a command prompt (to save startup time) we can pick our tests: [![](http://1.bp.blogspot.com/-myffmQYgpC8/TtfWhU5qTQI/AAAAAAAA_vM/uTxhOaHJSO4/s640/lein.png)](http://1.bp.blogspot.com/-myffmQYgpC8/TtfWhU5qTQI/AAAAAAAA_vM/uTxhOaHJSO4/s1600/lein.png) Note in the first case, we don't expect any tests to run (test! means fetch dependencies and then run tests) because our sole test has been marked as a :utility. In the second case, we tell it to run :utility and it does, telling us that our test passed. Success! If our test had failed, clojure's test suite would give us good information. Here, I'm going to modify the second assertion to fail. Watch what happens: [![](http://4.bp.blogspot.com/-CqWRxYR47_Y/TtfXz8Po9GI/AAAAAAAA_vU/RvqznnUbXSk/s640/lein-test-fail.png)](http://4.bp.blogspot.com/-CqWRxYR47_Y/TtfXz8Po9GI/AAAAAAAA_vU/RvqznnUbXSk/s1600/lein-test-fail.png) How cool is that? I've so far read Clojure in Action and The Joy of Clojure (both highly recommended), plus enough daily doses to actually stop mucking about and start with the CDT code already. So, a modern Lisp with powerful IDEs, modern libraries from the JVM , interactive REPL / TDD , great documentation, learning resources, and books — what's not to like?","tags":"Programming","title":"Lisp Conversion"},{"url":"http://adamgetchell.org/embedding-gists-in-blogger.html","text":"I went to the fabuluous CodeConf 2011 (view slides , recaps here , here , and here ) and the first talk was \"Tinker Fairy\" Dr. Nic telling us to build tools to do stuff that we don't want to remember later. Then build tools to build those tools — tool tools. One of the neat modern takes on Lisp s-expressions in modern virtual machines like the CLR is Reflection . At least, I think that it will be useful in reversing Lisp macros and expressions into the F#/ OCAML equivalents. Dr. Jon Harrop gives a terse but informative example in his book Visual F# 2010 for Technical Computing . First, we want a union type which represents (i.e. abstracts away) the F# type system: Next, we want a (recursive) function (called, straightforwardly enough, type_of) that reflects (using FSharpType) and translates a given System.Type object into one of the ‘a ty union types defined previously: This then allows us to emit the following two liner which can parse objects such as the List.fold function! (Note: everything after the ;; is the F# Interactive response.) Neat stuff! I've a thousand or two lines of Lisp to look at, so this is not something I want to have to remember later.","tags":"Programming","title":"Reflection tools for F#"},{"url":"http://adamgetchell.org/software-archaeology.html","text":"Vernor Vinge prophetically wrote of a time when programmer-archaeologists maintained the fabric of civilization by diving into and modifying legacy code which ran the systems that society depended upon. Various other folks have picked up on this notion, from the [serious](http://java.sys-con.com/node/487614) to the [humorous](http://giant-communist-robots.com/?p=154). Here, though, I'll talk about this from my own perspective (which is what you came here for, right?). [Kernighan's](http://www.ieee.org/portal/cms_docs_societies/sscs/PrintEditions/200804.pdf) saw goes that debugging code is twice as hard as writing it; therefore we ought to keep our meaning clear and our code as simple as possible. How to do so? There are clear debates about that: [functional vs. declarative](http://msdn.microsoft.com/en-us/library/bb669144.aspx), [procedural vs. object-oriented](http://www.virtuosimedia.com/dev/php/procedural-vs-object-oriented-programming-oop), not to mention [Patterns & Anti-Patterns](http://books.google.com/books?hl=en&lr;=&id;=HBAuixGMYWEC&oi;=fnd&pg;= PA383 &dq;=patterns+and+antipatterns&ots;=emzw4QN8Dj&sig;=AFOJ5TeY4zHfa1pCKky8ux_X9hQ#v=onepage&q;=patterns%20and%20antipatterns&f;=false), [Dependency Injection/Loose Coupling](http://martinfowler.com/articles/injection.html), [Aspect-Oriented Programming](http://en.wikipedia.org/wiki/Aspect-oriented_programming), etc. etc. These can be very fun to get into and there are diverse and subtle points all around, that I won't attempt to do them justice here but if you've a free week or two read any of the above links and the next five references thereafter and you'll come away more enlightened, or more confused. But in the meantime, you've either got to a) emit working code or b) manage those who do a). And if you could do so without too badly embarrassing yourself in the future (which is nigh impossible), or at least, be willing to chalk them up as learning experiences, you're well on your way to some sort of nirvana of ineffable, crystallized logic which is a perfect solution to your problem. (Getting a clear problem statement itself being at least half of the battle and most of the difficulty, given business processes that aren't well understood, or mutate depending upon who's doing them or in which context. But that discussion more properly belongs in the realm of project management and business analysis, and won't be further remarked upon here.) If you're not a coder yourself (or horribly out of date), you can still make a fair crack at judging the product by the team. [The Mythical Man-Month](http://www.amazon.com/Mythical-Man-Month-Software-Engineering-Anniversary/dp/0201835959) is the canonical reference, but [Joel Spolsky's](http://www.joelonsoftware.com/) [Joel Test](http://www.joelonsoftware.com/articles/fog0000000043.html) is pretty concise, descriptive, and useful. Archaeology can imply adventurous, sunburned types digging around fossil layers high in vast dusty mesas of stratified rock. And truth be told, that's not a bad analogy for the cacophony of systems that the average IT organization has inherited, cobbled together, purchased (often from a now-defunct vendor), or perhaps in a fit of creativity — produced. After all, post dot-com, [Greenfield development](http://footheory.com/blogs/donnfelker/archive/2008/05/05/software-development-greeenfield-vs-brownfield.aspx) is rare. But Brownfield development is often so painful that most developers will throw up their hands and rewrite from scratch, rather than attempting to piece together the workings of an often poorly documented system written with \"ancient\" methods/languages. Hence, onto the first item on the Joel Test: source control. But not just any source control. [GitHub](https://github.com/). Why GitHub? Well, first, it has the elusive \"Alpha Coder mindshare\". While it may not matter one way or another to your business that the Linux kernel, Git itself, jQuery, Ruby on Rails, and a host of other important projects exist on GitHub, it matters to your programmers, whether they know it or not (and the good ones will know it). All of these actively maintained open source projects provide something more interesting than mindshare: examples. Pick a programming language, and you will very likely find an interesting project or two on GitHub that has something worth learning. It may even prove to be the Rosetta stone of programming languages — you may find solutions to the same problem in many different programming languages. Second, [Social Coding](http://radar.oreilly.com/2009/01/github-making-code-more-social.html). Everyone knows of the usefulness of social networks — they existed before, but it's the tools that made them marketable/actionable. Social coding in GitHub takes the usual forms — followers, blogs, wikis, issues, teams, organizations — plus some more useful ones (e.g. the [GitHub API ](http://develop.github.com/)). We used Team Foundation Server. It was a nice tool in our . NET development shop — a bit painful to setup with it's dependence on SharePoint, but useful. However, it didn't scale too well in terms of collaborators. We needed to add them as users into Active Directory, fuss about with SharePoint and licensing, and so forth. So next we tried [CodePlex](http://www.codeplex.com/). CodePlex was, essentially, TFS in the cloud, and it mostly worked. There were capacity issues, and it wasn't always friendly with non . NET languages, but the main reason we didn't adopt it wholesale was: 1. No way to make private repositories 2. Often painful to connect into 3. Went down/was slow often enough that we didn't want to rely on it. This really illustrates the third virtue of GitHub, that it's a true cloud service — but cloud computing is all the hype right now and I really wanted to illustrate it's particular benefits in this instance. In going with GitHub, we created an organization for our, well, organization. This gives us several important advantages over CodePlex: 1. Private repositories 2. Teams 3. Unlimited collaborators (in particular, we can mix and match between general GitHub accounts and team members) 4. Blogs, Wikis, Gists, Issue Trackers with voting, per-line file commenting, and other social features 5. Works well with any programming language 6. Fast, decentralized development (Git works locally, so you can get on a plane, code, and upload your changes once you've got internet access) 7. Reliable versioning (Git uses hashes for files) 8. Works well with any OS / IDE (Git has integration with Visual Studio, Eclipse, XCode plus command-line versions in most every OS ) 9. Git is a well-regarded distributed version control system ( DCVS ) My programming team ported projects over from TFS and CodePlex in under a day. By following projects, I can watch check-ins, view version differences, open/close issues, and do all the usual software management stuff without getting in the way. (Or better yet, delegate.) The fees are pretty nominal (organizations get charged based on the numbers of private repositories they want; public ones are free). GitHub is hosted by RackSpace, so the reliability has been better than our in-house TFS boxes. Today I just added someone outside our organization to one of our projects with minimal hassle. If you're going to be digging up fossilized code, Git and GitHub are fairly pleasant tools for the job. Look at the time! This isn't really everything I wanted to say, but I've probably said enough for now (and I have other pressing priorities including my own research), so I'll leave further pontificating for another time. I hope this was informative, or at least, entertaining! (You can find me on GitHub [here](https://github.com/acgetchell)!)","tags":"Programming","title":"Software Archaeology"},{"url":"http://adamgetchell.org/socialism-capitalism-spending-oh-my.html","text":"For a change of pace, I'm going to ruminate on the state of affairs as I see them. (It's my blog, I get to exercise my [First Amendment](http://www.usconstitution.net/xconst_Am1.html)! ;-) (Yes, I'm procrastinating. The cluster is down for maintenance, and I need a break from technical reading and writing.) My Pop shared an interesting article during Thanksgiving, which noted that way back in the beginning of the direct founding of the U.S. A., colonists in the 1600's tried a form of socialism wherein the results of the season's harvest were shared equally amongst the colonists. (The account was written by the governor at the time, direct citations anyone?) The official noted that there were many deaths due to starvation, much inequity in terms of labor given vs. food received, and so forth. On the whole, the colony was in danger of perishing as the vicious cycle of famine made the remaining colonists weaker and less able to work, thus reducing the harvest, and so forth. In these dire straits, the next thing they tried was that they divided the land up equally amongst the families instead. Each family was free to keep the results of their work, and if they had excess, sell it for profit. The results were immediate: the next season's harvest was so bountiful that many families had excess, and those families that did not were able to buy from those that did. No one starved. The official also notes the changes in motivation (paraphrasing): \"Women who claimed infirmity and poor health when compelled to serve the community went willingly into their own fields with their children. The high (and unacceptable) costs that might have necessary to compel this behavior were no longer required …\" Score one for capitalism, individual thrift and perseverance, and …. But wait. Where did they get the land? Oh, that's right. **They were given it.** Or, from another perspective, perhaps they stole it. (I don't want to get into those issues since there's even more controversy about that and it's incidental to my point.) The point is: the colonists were given the tools to feed themselves, and they then were allowed to make their own way. Capitalism is a fine system for efficient distribution of goods, services, and products. But it was an act of socialism (specifically, the land grant) that gave those first colonists the means to start on their new lives. (They had to supply the effort.) We're no longer an agrarian society. We're an [information one](http://en.wikipedia.org/wiki/Information_society). What are the tools needed to make our way today? I'd argue for these, in descending order: 1. Health 2. Free flow of people, goods, services, and information 3. Education 4. Stability I'd also argue that lack of any one of these items is problematic. That last item may be even more difficult to quantify, except that you know it when you see it: wars, famines, natural disasters, stock market crashes, etc. Things too big for any individual or family to handle alone, something that requires a societal solution. The world is [chaotic](http://stason.org/ TULARC /science-engineering/nonlinear/index.html). Trying to impose too much stability results in a dead/fragile/stratified society (see history for numerous examples). Too little, and [no one can plan for the future](http://en.wikipedia.org/wiki/The_Road). We are a [mixed socialist/capitalist society](http://en.wikipedia.org/wiki/Mixed_economy). Go towards any extreme for any of the above, and we will suffer. Define suffering: again, you know it when you see it. Death, disease, famine, wasted lives, inability to meaningfully affect your own destiny, loss of freedoms, etc. These are broad brush strokes, individuals/society will naturally have their own values. So how do we provide the above to our citizenry in our society? How do we give the tools to be successful, without redistributing the results of that success [unfairly](http://en.wikipedia.org/wiki/Fair_division)? (This is not meant as an exhaustive analysis, but a mere framing of the problem.) Government spending: Now let me say from the outset, that like general relativity, I prefer solutions to be as localized as possible. I'd also like to remain as free as possible from any equations of constraint enforced by some larger entity. I don't dispute that some are necessary (anarchy is cool until you live in it), but I wonder if we are half as good at **removing laws** as we are at [making them](http://law.justia.com/). These entities need money to do their work. Right away that suggests a neat solution: [don't give them any](http://en.wikipedia.org/wiki/Laffer_curve). Unfortunately, that only works if you already have the means to provide the 4 items mentioned above. Clearly, not all individuals do, so a society based strictly upon \"to each their own\" would be [manifestly unfair](http://en.wikipedia.org/wiki/Plutocracy), and I do retain the silly idea that [the universe ought to be as fair as possible](http://www.theonion.com/articles/universe-admits-to-wronging-area-man-his-entire-li,18556/). (Oh wait, we're already a [plutocracy](http://en.wikipedia.org/wiki/Lobbying_in_the_United_States).) Now spending itself is a moderately abstract formulation of reality: there are only so much goods, services, information, and time available. Spend less than you make, and you have savings: for a rainy day, or to help someone else start something they couldn't otherwise do (perhaps with the hopes that you'll be compensated in the future for lending your resources today). Spend more than you make (if you're allowed to), and you have debt, or future restrictions on your earning potential. Pretty straightforward stuff. It seems that Americans in general are now used to the consumption economy fueled by credit and debt, and we've passed that along to our government. Or perhaps it's the other way around. That's a fairly common rant, and I'll not repeat it except to say: we've obviously hit the limit on how much debt (monetary, environmental, etc.) we've incurred, and we should be looking to pay it off instead of increase it. This seems pretty simple to say and do, but let's watch how events unfold and see if the [politicians actually realize](http://paul.house.gov/index.php?option=com_content&view;=article&id;=1799:dont-raise-the-debt-ceiling&catid;=31:texas-straight-talk) that our government cannot continue to live beyond its means. At least the [Fiscal Commission](http://www.fiscalcommission.gov/) is a start, although of course there are economists [who think it's not a problem after all](http://www.csmonitor.com/ USA /Politics/2010/1203/Is-deficit-commission-wrong-Critics-say-there-s-no-national-debt-crisis.). I'm not an economist, but there seem to be some pretty [instructive examples](http://www.csmonitor.com/Commentary/the-monitors-view/2010/1202/After-the-deficit-commission-on-to-Plan-B) that indicate otherwise. Okay, back to considering things I have somewhat of a clue about. ** ** ** **","tags":"misc","title":"Socialism, Capitalism, Spending, oh my!"},{"url":"http://adamgetchell.org/cdt-rewrite-toolbox.html","text":"So, my colleagues have developed a CDT program that's usable. Fortunately for me, it's in LISP , which lacks parallel processing, modern libraries, a nice IDE , and the other goodies I've become accustomed to in my work life. (That means I get to figure these features out and thereby contribute!) Enter Visual Studio 2008, IronPython , and IronScheme . Setting up IronScheme with Visual Studio 2008 was usefully detailed here : (note, you need RegPkg via the Visual Studio 2008 SDK ) Setting up IronPython with Visual Studio 2008 via IronPython Studio (integrated setup) : And voila, no more excuses to complain about development. (Yes, the end goal is to make it Python and cross-platform, although I'm really eying F#)","tags":"Programming","title":"CDT rewrite toolbox"},{"url":"http://adamgetchell.org/nobel-pursuit.html","text":"Well, the Nobel Prizewinners are to be announced ~~tomorrow~~Tuesday. In the spirit of fun (and to demonstrate how much science really does advance), here are some predictions and other fun facts gleaned from around the ‘Net: Can you predict the Nobel Prizewinners in Chemistry & Physics by counting citations? Apparently not: http://www.symmetrymagazine.org/breaking/2008/08/27/nobel-prize-citations/ Since this is an election year, it's interesting to note that 61 Nobel Laureates (including 22 physicists) — the highest ever — support Barack Obama for President: http://sefora.org/2008/09/25/61-nobel-laureates-in-science-endorse-obama/ Perhaps it's because Obama/Biden actually have a cogent science policy , and happen to believe scientists when they talk about evolution or global warming. Interestingly, Reuters seems to think citations count for potential Nobel prizewinners: http://physics.about.com/b/2008/10/04/2008-nobel-prize-coming-soon.htm They think the contenders are: Vera Rubin at Carnegie Institute in Washington for her work on Dark Matter Andre Geim and Kostya Novoslev for Graphene Physics World offers the following candidates: Daniel Kleppner at MIT for inventing the hydrogen maser Berkeley's Saul Perlmutter and Brian Schmidt at the Australian National University for their discovery that the universe's rate of expansion is increasing …leading to the concept of dark energy MIT ' s Alan Guth and Andrei Linde at Stanford University for their work on inflation Chapman University's Yakir Aharanov for the Aharanov-Bohm effect and Michael Berry at the University of Bristol for the Berry phase — the AB effect being related to the Berry phase John Pendry of Imperial College and Duke University's David Smith for their prediction and discovery of negative refraction Roger Penrose at Oxford University and Cambridge's Stephen Hawking for their contributions to general relativity theory and cosmology Atsuto Suzuki from Japan's SuperKamiokande experiment and Art MacDonald from SNO in Canada for their work on neutrino oscillations Who am I going to pick? Well, not because of any insight, but because of fondness for the topic I'm going with one of the cosmological predictions, either inflation, dark matter, or dark energy. Maybe they'll all be grouped together. Tune in ~~tomorrow~~Tuesday to see who wins! Update: Nambu (of the Nambu-Goto action for bosonic string theory), Kobayashi and Masakawa (of the Cabbibo-Kobayashi-Masakawa matrix which describes flavor-changing weak decays) share the Nobel prize for Physics in 2008 , quite deservedly, for discovery of spontaneous symmetry breaking .","tags":"Physics","title":"A Nobel Pursuit"},{"url":"http://adamgetchell.org/causal-dynamical-triangulations.html","text":"Rajesh Kommu and Professor Steve Carlip are working on interesting ways to model quantum gravity using computational methods. Rajesh has been kind enough to help show me where to get started: Dynamically Triangulating Lorentzian Quantum Gravity A non-perturbative Lorentzian path integral for gravity Non-perturbative 3d Lorentzian Quantum Gravity Spectral Dimension of the Universe As things often do, it turns into code, which Rajesh has again provided. Of course, Visual Studio 2008 Beta 2 has some … issues with the STL . So, in the interest of getting working code I'll try a virtual instance of Ubuntu which I should be able to upgrade later when 7.10 comes out later this month). VMWare server requires IIS7 , so here's the instructions for installing IIS7 on Vista . Except that I couldn't connect to my own VMWare server, and apparently VMWare has issues on Vista … sigh. Okay, it seems to be a driver signing issue . Meh … Virtual PC 2007 will probably suffice for my purposes. I'll keep IIS7 .0 anyways for when I install Visual Studio 2008 Release Candidate and want to develop against IIS . … Except that Virtual PC 2007 apparently doesn't know how to handle Ubuntu. Just hangs at the nice pretty install screen, wasting CPU cycles. Back to VMWare server. Looks like I can disable driver signing permanently using an admin console: bcdedit.exe /set nointegritychecks ON bcdedit -set loadoptions \\DISABLE_INTEGRITY_CHECKS Let's try this again. Hmmm, that *still* didn't disable driver signing. So, bootup using F8, disable driver signing. Now install VMWare Server 1.04. This time, I'll pick a slimmer linux distribution, like Xubuntu . I have to admit, nice, slick, easy install. Not as fast as OpenBSD ‘s bare-bones, efficient text setup, but it's pretty, and more importantly, it works (unlike the heavier Ubuntu desktop I just tried). Now install VMTools. Oh, it's an rpm. Fortunately, there are ways to install using an RPM file . Hmmm. Should I be surprised that this didn't work? Okay, back to installing a tarball. That worked, even though it also overwrote pre-existing stuff from the RPM . Actually, no it didn't. It just stopped VMWare from nagging that VMTools isn't installed. I'll just deal with the mouse capture for now, because this really all is besides the point. (Note to self: more empathy for people just trying to get their work done using computers.) Some things never change. Xubuntu has 84 updates to patch! Well, the whole point of this was to compile this under Linux (where Rajesh wrote it) instead of tailchasing Visual Studio 2008/C++ STL issues. Almost there! Now to find a decent IDE . I've heard good things about Eclipse, but I don't really want to unpack Java, install Tomcat, Web Tools , etc. etc. when I don't plan to do any web development. I just want the C/C++ portion. Ah, CDT looks like what I want. Is the magic incantation really: # sudo apt-get install eclipse-cdt # sudo apt-get install eclipse Wow, looks like it is! Now to see if Rajesh' CDT code compiles …. Okay, right now Eclipse is a tad confusing. And again, learning Eclipse isn't the point. Let's go back to that old standby, vi. Sure helps to have a c++ compiler installed # sudo apt-get install g++ Well, okay, looks like I'm missing some other files. Make doesn't know how to make cdtworks. A structural issue. So, when something fails, try something else … Made some more progress on the Windows VC ++ 9 version. Turns out, even though the project files were stored in my C:\\Projects file, Visual Studio had other ideas, and expected everything to be stored in the Visual Studio default file path. I'll just leave that one, since the default file path ends up getting stored on our SAN , whereas I've had the most lovely fun with hard drives and Bitlocker (which is again, besides the point). Almost complies, although VC ++ wants all header file declarations in stdfx.h. Just missing one file … again! On the other hand, now I can read code in two OSes. Sure is interesting dereferencing all those pointers! Quantizing spacetime is fun, though!","tags":"Physics","title":"Causal Dynamical Triangulations"},{"url":"http://adamgetchell.org/causal-dynamical-triangulation.html","text":"The papers to read to get started: A discrete history of the Lorentzian path integral Reconstructing the Universe Then the usual: Dynamically Triangulating Lorentzian Quantum Gravity Emergence of a 4D World from Causal Quantum Gravity Semiclassical Universe from First Principles Spectral dimension of the Universe (Thanks to this post from Marcus) And finally, the current literature on ArXiv.","tags":"Physics","title":"Causal Dynamical Triangulations updates"},{"url":"http://adamgetchell.org/are-we-living-in-simulation.html","text":"Today I came across one of Dr. Nick Bostrom's existential philosophy papers regarding life vs. sim-life (aka are we living in the Matrix?). To me, the really interesting question is the assumption of substrate-independence (because I don't believe we're living in a simulation, more on that in a bit) — that sentience , sapience , and self-awareness can arise from any appropriately complex material, including computer processors. Is there some minimal complexity bound for intelligence? (First, tell me what you mean by intelligence .) On one hand, we already know that a virus is just a particular aggregation of molecules, and that any assemblage of those particular atoms will exhibit the same viral behavior. On the other, does that extend to a connection between viruses and the rest of the living world, and by analogy, to bottom-up intelligence? Will computers be able to exhibit sentience, sapience, or self-awareness? As an aside, although most people seem to know Seth Lloyd's paper on the ultimate limits of computing, I tend to prefer Warren D. Smith's Fundamental Physical Limits on Computation and Fundamental physical limits on information storage as being more useful equation-wise (and he has very interesting papers on election systems and voting , which doesn't surprise me when it concludes that our current voting system is nearly the worst mathematically possible, and that Range Voting is a much better algorithm ). (Note that some the papers are in PS format, so you will need a PostScript reader such as GSview along with GPL Ghostscript to read.) Before I get too sidetracked, let me outline my reasoning for why I don't believe we're living in a simulation: The total entropy/information of our Universe is bounded at \\< 10E123 (due to the Holographic principle ) A simple quantum computer with 500 entangled pairs generates more information than could be simulated by any non-quantum computer in this Universe (2\\&#94;500 >> 10E123) If the Universe is not simulated to a quantum degree of accuracy, the simulation can be immediately exposed via Bell's inequality Thus, in order to create a virtual universe sufficient to withstand experimental quantum physics tests, you need 10E123 qubits (e.g., the Universe) Anyways, this is a very interesting topic, but I should continue my sidetracking avoidance and get back to my research.","tags":"Physics","title":"Are we living in a simulation?"},{"url":"http://adamgetchell.org/cosmology-and-quantitative-biology.html","text":"Went to an interesting seminar today about detecting traces of the reheat portion of the Hot Big Bang (the part that occurs after inflation), papers not yet out on arxiv (links posted here when they come out). The interesting bits to relay back here are: Any symmetry breaking (Higgs, for example) invariably generates gravity waves. Thus, it's possible for to use gravity waves to probe all the way back to inflation, 10E-35 seconds. These gravity waves can be, in principle, detected by tabletop sized experiments! (There's a group trying to do that now). Unfortunately, there are issues of sensitivity that will make this rather difficult, but perhaps by, oh, 2020 we may detect relic gravity waves in the same way we've already detected the CMB . Another cosmic relic is leftover magnetic fields, of which theory predicts their strength and scale should be equivalent to what we're seeing today as galactic and intragalactic magnetic fields. Our guest seemed to expect to see copious production of strings and textures, which should be signified by their gravitational traces and provides further experimental tests of the stringscape . And in some other news, here's a really fascinating article on bateriophages (viruses that infect bacteria) with some really nifty discussion points related to our nanotech thread. I won't spoil the article, it's well worth the read (it serves as a handy primer for nanotech issues), but an interesting result is the calculation of pressure inside the hard shell of a bateriophage, with experimental support, which shows that: Bacteriophages have double-helix DNA to serve as a spring to provide packing energy Bacteriophages rely upon this pressure to propagate, at least initially, into bateria. Viruses are basically mechanical, inanimate objects. They don't do anything except replicate, and any inanimate matter assembled into the particular protein configuration of a virus will behave like that virus; on the flip side, viruses have the exact electrical properties of any other similar-sized particle in a colloidal suspension.","tags":"Physics","title":"Cosmology and Quantitative Biology"},{"url":"http://adamgetchell.org/undecidability-regularity-and.html","text":"Modern space-time and undecidability Quantum Decoherence","tags":"Physics","title":"Undecidability, Regularity, and Decoherence"},{"url":"http://adamgetchell.org/ultra-strong-electric-and-magnetic.html","text":"Response of Polyatomic Molecules to Ultrastrong Laser- and Ion-Induced Fields Physics in Ultra-strong Magnetic Fields","tags":"Physics","title":"Ultra-strong electric and magnetic fields, monopoles"},{"url":"http://adamgetchell.org/dynamical-triangulations-sage.html","text":"The first paper I read for Causal Dynamical Triangulations is a fairly steep introduction (for me), so I went and looked over the 2D case and lessons , as well as a general review of methods. I'm also looking at SAGE , Software for Algebra and Geometry Experimentation, a free mathematical programming system using Python + a lot of open source tools. On Windows, SAGE requires VMWare and uses firefox. You can use it online , but so far it's rather slow, and appears to have been slashdotted . Impressive tool! Feels a lot like Mathematica, accessible via web browser. The tutorial is well-worth running through (I used the on-line version while upgrading my local install, but the local version allows you to run the calculation cells using Shift-Enter ). For example, SAGE extends Python to handle rings and p-adic numbers (which I learned, should always have a prime number base to avoid the zero-divisor problem). Adding dvipng SAGE package requires adding ghostscript, via apt-get install gs. Also requires libkpathsea, which requires tetex via apt-get install tetex-extra PostScript: the SAGE dvipng package doesn't work, but apt-get install dvipng puts dvipng on the system, which should suffice. Note: SAGE runs on Edgy, and can be updated to Feisty by using update-manager-core as described here . The SAGE -support group is available on Google Groups. PostScript: SAGE can be upgraded to Gutsy, I used the Upgrade Manager available in Xubuntu (I wanted a GUI for some SAGE file management via apt-get install xubuntu-desktop) Doesn't work yet on BSD , alas, and running a SAGE server has security implications.","tags":"Physics","title":"Dynamical Triangulations, SAGE"},{"url":"http://adamgetchell.org/projecteuler-on-f.html","text":"So, whilst poring through Pickering's book and browsing through Tomas Petricek's blog (which has a promising F# AJAX toolkit , which alas, doesn't work yet) and stealing glances at the O'Reilly online OCAML book , I decided to write some programs to exercise my understanding of the material. After some stumbling, I found Project Euler , a great site full of math programming puzzles. I solved Problem #1 naively in \\~ 10 lines of F# using list comprehensions and recursion (I've seen a one-liner using Seq.fold). Problem #2 builds on this and takes about 30, including a debugging function to print results ( better solutions , using Seq.unfold, do it in 10). I posted my code solutions to the forum , so as not to spoil anyone else's fun (you can only post to the forum for that problem after you've solved it). It's very interesting to see all of the other solutions in different languages, and the algorithm discussion is fascinating too. It's also quite impressive how easily F# morphs into math problems (though I am still writing some horrid C#/F# hybrid presently). Oh, and here's a nifty 100-line podcast downloader, slurppodcasts . (Note that Idioms.using is no longer necessary, since using is integrated into F#) Finally, here's Feedburner's Planet F# .","tags":"Programming","title":"ProjectEuler on F#"},{"url":"http://adamgetchell.org/f-regge-calculus-and-other-interludes.html","text":"Still working on Causal Dynamical Triangulations , I've also taken some time out to (start to) learn a delightful new functional programming language, F# , with the help of a good site , online journal , and this book . Mixing functional, imperative, and object-oriented programming with good mathematics features and the . NET framework allows me to blend work and academics. The goal is to write a first-cut CDT program in F# and refine as necessary …. CDTs depend upon Regge calculus , which is essentially a prescribed way for dividing up spacetime into a discrete lattice (simplexes) while adhering to the Einstein field equations. (Regge calculus is explained in detail in Chapter 41 of Gravitation, aka the Big Black Book .) In particular, you divide up a smooth 4-manifold into a collection of 4-d simplexes, in the same way you can divide up a 3-sphere into the (2-)triangles of the icosohedron. If you pressed the icosohedron perfectly flat onto a plane, you would see deficit angles or hinges that essentially reflect the its spherical curvature. In the same way, you analyze the simplices of the 4-d manifold to determine its curvature. If you are extraordinarily careful in how you setup your lattice, you can perfectly constrain your volume using just fixed edge lengths. (For example, a tiling of triangles constrains a surface rigidly, because the tiling cannot be deformed without changing edge lengths. A tiling of squares does not, because the squares can be squashed sideways into parallelograms without changing their edge lengths.) And if you do this, you can now examine that volume (or brane, or bulk ) by solving the Einstein equations expressed in terms of conditions on the hinge angles (which are themselves functions only of the edge lengths). This is exciting because you can now program a computer (carefully) to solve problems that don't lend themselves to analytic solution, which allows you to do interesting things: Discrete quantum gravity in the framework of Regge calculus formalism In the past few weeks, I've also taken time to read up on a few areas of interest. Perhaps one of the more interesting recent occurrences is the recent re-examination of the 2nd law of thermodynamics, long thought to be inviolable and one of the most solid foundations of physics by such luminaries as Maxwell, Einstein, Eddington, and Brilloun. Physics is always fun, check your assumptions at the door! First, a nice publicly accessible summary: Why Do We Believe in the Second Law? , T. Duncan The Foundations of Physics journal, Volume 37, Number 12/December 2007 is devoted to this extraordinary topic (unfortunately, e-journal subscriptions required to view), starting with Geraard t'Hooft's editorial , which gives a broad summary of the scope of the papers in the journal. Next, we have: The Second Law of Thermodynamics: Foundations and Status , by D.P. Sheehan This paper gives a broad overview on three classes of discussion regarding the Second Law now underway: ideal gases, quantum perspectives, and interpretations. Information Loss as a Foundational Principle for the Second Law of Thermodynamics , by T.L. Duncan and J.S. Semura This paper explores in detail the concept of information loss as being the fundamental explanation for entropy, essentially casting the 2nd law from \"Entropy always increases for irreversible processes\" to \"Information is always lost for irreversible processes\". The authors further argue that all classical derivations of the 2nd law using \"entropy\" actually incorporate, explicitly or implicitly, information loss as the mechanism. As an example, Maxwell's demon is shown to be able to violate the 2nd law on the basis of having information — in particular, knowing how to sort fast-moving from slow-moving particles. However, creation of that information eventually involves the deletion of a bit of information from storage — for a subsequent Kln2 energy cost — which is argued as being the source of entropy. (All faults are mine, not the authors, if I've paraphrased these arguments incorrectly.) Jean E. Burns, in Vacuum Radiation, Entropy, and Molecular Chaos , makes a very interesting extension to classical entropy models for isolated systems. Classical thermodynamic models separate the system from the environment. The canonical example is the refrigerator, which decreases temperature (thus entropy) locally, but at the expense of expelling even more heat (thus increasing entropy) in the environment. The entropy/heat loss inside the system is outweighed by the entropy/heat gain in the environment. However, what happens for an arbitrarily large system (such as the universe), where there is no external reservoir? Burns argues that vacuum radiation provides the mechanism for entropy increase. Perhaps of most interest to biologists and science-fiction fans is Sheehan's Thermosynthetic Life , which postulates the existence of life forms deriving their energy solely from thermal energy. In addition to searches for extremophile lifeforms (such as bacteria near volcanic vents) that fit this profile, it provides an engaging test into the 2nd Law, because such life-forms may well violate it! And, continuing on with our examinations into entropy and information theory, we have: Information Recovery from Black Holes , V. Balasubramanian, D. Marolf, and M. Rozali This first-place prizewinning essay of the 2006 Essay Competition of the Gravity Research Foundation provides insights into two crucial questions: Why do classical black holes have finite entropy equal to a quarter of the horizon area? How does information escape from an evaporating black hole? In essence (modulo a great many technical arguments), the answer to both of these questions is that the finite mass black hole, representing a finite number of energy states N, therefore possesses a discrete energy spectrum. In general, discrete spectra are quantum-mechanically non-degenerate, so knowledge of the precise energy and other (commuting) conserved charges determines the quantum state. But General Relativity charges are generically given by boundary terms; thus, the entire state of the black hole resides in the boundary (asymptotic region), available to all observers. This is at odds with classical GR , because there exist unobservable regions within the black hole that are causally separated. However, in the quantum mechanical case the Heisenberg Uncertainty principle dictates that a \"Heisenberg recurrence time\" exists. This can be thought of as a sort of spontaneous large thermal fluctuation in which the black hole may be replaced by a ball of expanding hot gas. Although the gas will re-collapse to form another black hole on a relatively short time scale, during the span of its existence the full details of the black hole's internal state are visible from infinity. And thus we see that at the quantum level, the event horizon becomes ill-defined, and quantum mechanics, entropy, and information theory collaborate against General Relativity to allow what was previously thought to be impossible. And in a final bit of fun, we see a method for efficiently converting black holes into gravitational waves: Black Hole Bremsstrahlung: Can it be an efficient source of gravitational waves? Taking a 2 solar mass black hole traveling at .38c and converting 90% of its rest mass into a lobe-shaped pulse with width deltaU \\~ 40 for 10E40 GeV\\&#94;2 sounds exciting!","tags":"Physics","title":"F#, Regge Calculus, and other interludes"},{"url":"http://adamgetchell.org/holomorphy-and-friends.html","text":"I'm reading Chapter 8 of Modern Supersymmetry . To understand the first sentence, I had to review Maldacena's paper , which (not-so) incidentally proposed the AdS/ CFT correspondence (hence its numerous citations ). Hmmm. I'll have to read it again. ;-) But moving on … Okay, now need to review non-renormalization theorems and Wilsonian effective action . Wow, lots to catchup!","tags":"Physics","title":"Holomorphy and friends"},{"url":"http://adamgetchell.org/quantum-parallel-universes.html","text":"Professor Andy Albrecht has kindly pointed me to one of a series of papers by David Deutsch that begins the proof of Hugh Everett's Many-World's Hypothesis : Quantum Theory of Probability and Decisions This paper removes the requirement to have a probabilistic interpretation of quantum mechanics, instead casting it into a non-probabilistic decision theory basis. The main result is that the usual probabilistic formulation can be replaced by a rational decision maker using classic decision theory. Furthermore (and most importantly), quantum processes whose outcomes look stochastic can be replaced by deterministic evolution of states. Note that this neatly removes the issues around definitions of probability in the MWI . I'm now taking, for fun, an advanced Supersymmetry class , taught by Prof. John Terning, which picks up where my last SUSY class left off. Wow, I need to review !","tags":"Physics","title":"Quantum Parallel Universes"},{"url":"http://adamgetchell.org/new-direction.html","text":"After a long hiatus, I'm back … Back to what? Well, most of that hiatus was due to work, and I already keep a (boring) work journal. But the main thing is I'm back to doing physics … The goal is to start (and finish) a dissertation in Computational Quantum Gravity. What does that mean, exactly? Well, that's the whole point of the journey — and this blog will help me track my progress. It may not be that interesting to you to read, but it will be useful for me to write, and keep notes, with. And a goal left unstated is left undone — that's why it's all hanging out here. So the first order of business is to get really comfortable with LaTeX . Next, it would be really nice to be able to post equations here. Oh, looks like someone's already hacked that together . The Einstein equation: Here's a really good intro summary on the state of the art on quantum gravity: http://plato.stanford.edu/entries/quantum-gravity/ With a reference to the classics: http://math.ucr.edu/home/baez/einstein/einstein.html http://math.ucr.edu/home/baez/gr/gr.html Well, that should be enough to start with this weekend!","tags":"Physics","title":"A new direction"},{"url":"http://adamgetchell.org/fun-with-microsofts-enterprise-library.html","text":"Oh yeah, back to my day-job: I'm a programmer. So we've got a new application to update the current stone-tablet process in the University that determines if students actually graduate. Now, I like to write good code, and furthermore, if someone else writes it for me, that's even better. So if you are working on the . NET platform, you'd do well to look at the Enterprise Library . Of course, this is several thousand lines of code to pore over, good stuff, but unfortunately we have these minor annoying things called deadlines which prevents us from taking the time to grok everything properly. Come to think of it, this happens in Physics, too — I never have enough time to actually understand all the details of the problems I'm supposed to be solving, but my advisor assures me that this is the proper state of things in research, as opposed to writing text books, and three guesses as to which one gets you tenure. Back to the matter at hand — the Enterprise Library. Looking around at some good working examples , hilarity and pandemonium ensues when you try to do something simple like write to the Event Log when your application barfs. (Did I mention this doesn't come up a lot because instrumenting software seems to be a … novelty?) I'm pretty sure that developers should not be doing things like editing the Registry, installing Services, or setting accounts programs run under with full admin rights — I was a system administrator in a previous job, and I hated letting programmers do those kind of things. So I won't inflict the same damage on our own, long-suffering sysadmin. Now, my 52-line class solution doesn't do all the bells and whistles the EL does, but it sure doesn't require all the nastiness above: using System; using System.Diagnostics; namespace CAESDO { /// \\ /// Methods to handle error reporting /// \\ public class ErrorHandler { public ErrorHandler() { // Register application as source for Application log if (!EventLog.SourceExists(\"FacultyStudentSurveys\")) EventLog.CreateEventSource(\"FacultyStudentSurveys\", \"Application\"); } /// \\ /// Writes an error message to the Application Event Log /// \\ /// \\ The thrown exception \\ internal void WriteToEventLog(Exception error) { const string source = \"Commencement\"; const string logName = \"Application\"; EventLogEntryType enumType = EventLogEntryType.Error; EventLog objectLog = new EventLog(logName); objectLog.Source = source; objectLog.WriteEntry(error.Message, enumType, 1 ); } internal void WriteToEventLog( string message, bool success) { const string source = \"Commencement\"; const string logName = \"Application\"; EventLogEntryType enumType; if (success) { enumType = EventLogEntryType.Information; } else { enumType = EventLogEntryType.Error; } EventLog objectLog = new EventLog(logName); objectLog.Source = source; objectLog.WriteEntry(message, enumType); } } } I'm sure I've missed something obvious. Anyone? I just got a reply from the Hisam Baz, author of the above weblog which says, \"Why write 52 lines of code when you can write 1?\". To which I reply, \"I'd be happy to write 1 line of code — if it works.\" Which brings us to the second problem: Non-portable references to the Global Assembly Cache in ASP . NET Once you actually try to use the Enterprise Library, you'll often come across this bit of advice: \" References Then from your application, add references to Microsoft.Practices.EnterpriseLibrary.Configuration.dll and Microsoft.Practices.EnterpriseLibrary.Logging.dll from the C:\\Program Files\\Microsoft Enterprise Library\\bin\\ directory. You should consider signing the assemblies and then adding them to the GAC . You should also add a copy of the assemblies to C:\\Program Files\\Microsoft Visual Studio . NET 2003\\Common7\\ IDE . Once you do that, you can select the assemblies directly from the \"Add Reference\" dialog. One you've added the reference, then add the appropriate using statement - using Microsoft.Practices.EnterpriseLibrary.Logging - to your code.\" There's only one problem — it doesn't work. When Visual Studio 2003 . NET looks for references in the Global Assembly Cache, it never updates its view of the GAC in response to what you've added — that's done by the registry (bleah). Which is why you've got to add a copy where VS can find it. When writing ASP . NET applications, references should be against assemblies in the webserver GAC . And naturally, installer projects written in VS 2003 do not install the files in the GAC automatically, as they do for the web application itself. So now you have to manually add assemblies to the GAC and write registry entries for each assembly to be resolved by the . NET runtime. Wait, why are we using the GAC again? Okay, looks like I'll have to wade through Richard Grime's Fusion Workshop . Except that it doesn't cover the case I'm interested in. Joy. Well, I sure hope that the 10 lines of code I'll end up emitting in this exercise will exceed the several thousand I could be writing if I just wrote everything myself. What's that again about the virtues of programmers? Laziness, impatience, and hubris. Oh, alright then.","tags":"Programming","title":"Fun with Microsoft's Enterprise Library"},{"url":"http://adamgetchell.org/fun-with-microsoft-enterprise-library.html","text":"Okay, I can see that this is going to be a long series …. Here's what I'm talking about on how to get Visual Studio to see Enterprise Library assemblies without browsing (taken from the GotDotNet workspace patterns & practices: Enterprise Library: Message Boards): \" Do you want to see EntLib assemblies in Add References message box? Create a text file named entlib.reg, and add this content: Windows Registry Editor Version 5.00 [HKEY_LOCAL_MACHINE\\ SOFTWARE \\Microsoft\\VisualStudio\\7.1\\AssemblyFolders\\Enterprise Library] @=\"C:\\Program Files\\Microsoft Enterprise Library\\bin\\\" Double click on the file and you'll be asked whether to add this registry key. Click yes, restart vs.net and there you go. (it is assumed that assemblies are in their default folder - otherwise, change the path above). \" Sigh. I really really try to avoid the Registry when possible. There's another neat trick for sorting out the structure of the Enterprise Library: open one of the solutions in Visual Studio, select Project-> Visio UML -> Reverse Engineer. Too bad all it actually does is generate a 75K blank Visio file, because Visio is unable to resolve all of the references. I suppose this will work for code that's so simple that a UML diagram isn't needed. Moving right along, I've also found how to sign all of the Enterprise Library Asemblies! You just generate your public/private key pair, and then reference them in the GlobalAssemblyInfo.cs file in: C:\\Program Files\\Microsoft Enterprise Library\\src This file gets referenced by every project when it's compiled. Yay! Except that every project's AssemblyInfo.cs contains blank references: [assembly : AssemblyDelaySign(false)] [assembly : AssemblyKeyFile(\"\")] [assembly : AssemblyKeyName(\"\")] Which overwrite what gets pulled in from GlobalAssemblyInfo.cs. So you have to go through every project's AssemblyInfo.cs file and remove those 3 lines. Sigh. There's 23 projects in the Security section alone, which is sort of the sine qua non for using the EL to begin with, for my purposes. Well, Caching, Configuration, Data, ExceptionHandling, and Logging are also useful. One step at a time. I've gotten Logging to work. Unfortunately, every time it logs it throws three error messages: \" Failed to create instances of performance counter ‘Distributor: # of Logs Distributed/Sec' - The requested Performance Counter is not a custom counter, it has to be initialized as ReadOnly.. For more information, see Help and Support Center at http://go.microsoft.com/fwlink/events.asp.\" \" Failed to fire the WMI event ‘LoggingLogWrittenEvent'. Exception: System.Exception: This schema for this assembly has not been registered with WMI . at System.Management.Instrumentation.Instrumentation.Initialize(Assembly assembly) at System.Management.Instrumentation.Instrumentation.GetInstrumentedAssembly(Assembly assembly) at System.Management.Instrumentation.BaseEvent.Fire() at Microsoft.Practices.EnterpriseLibrary.Common.Instrumentation.InstrumentedEvent.FireWmiEventCore(BaseEvent baseEvent). For more information, see Help and Support Center at http://go.microsoft.com/fwlink/events.asp.\" and \" Failed to create instances of performance counter ‘Client: # of Logs Written/Sec' - The requested Performance Counter is not a custom counter, it has to be initialized as ReadOnly.. For more information, see Help and Support Center at http://go.microsoft.com/fwlink/events.asp.\" Presumably these counters are installed as part of the EL service installation, but going through the batch file yields for logging: @ ECHO . @ ECHO ————————————————————————————————————————- @ ECHO Installing Services for the Logging and Instrumentation Application Block @ ECHO ————————————————————————————————————————- @ ECHO . if Exist Microsoft.Practices.EnterpriseLibrary.Logging.dll installutil %1 Microsoft.Practices.EnterpriseLibrary.Logging.dll @if errorlevel 1 goto :error So I'd like to break out whatever counters are needed so I can install them on the webserver, and ideally, be able to script this installation for production code on a production server with an Installer project. Although I'm strongly tempted to just go back to using my ErrorHandling class, which doesn't need anything installed anywhere. No, I'll persist in using the EL . I'm sure there will be a payoff — like extending the Logging class to handle XML . Of course, to extend the EL one should be cognizant of all the Unit Tests there built to ensure its continued functionality. So I need that book on Test Driven Development real soon now. Well, at least I'm not bored.","tags":"Programming","title":"Fun with Microsoft Enterprise Library, part 2"},{"url":"http://adamgetchell.org/microsoft-security-awareness-training.html","text":"This is just too funny to pass up. So far, malware's winning the war of attrition . Well, at least Microsoft Anti-Spyware is going to be free. Too bad there's already malware which targets it . You do have a real hardware firewall, don't you? If not, there's no reason why you shouldn't — here's my OpenBSD recipe that works beautifully on inexpensive hardware, and has big-bucks features like stateful filtering, source tracking, bandwidth queuing, NAT , OS detection, adaptive state table timeouts, MAC address tagging (with brconfig), macros and tables, and hardware failover capability. All for the price of an OpenBSD CD and whatever hardware you run it on. (One of the firewalls I set up for a class C network was a Pentium 166 with 32MB of RAM , and it mostly sat at 99% idle filtering a 100MB full-duplex LAN . OpenBSD has a very efficient network stack. When I've gone around to help setup OpenBSD firewalls for departments at UC Davis, we mostly recycle leftover desktops that have been replaced.) Of course, to help deal with malware you'll also have to do egress filtering (not just ingress filtering, where most rulesets stop), and as always, keep your systems patched. But then, there's no such thing as a panacea. Did I also mention that pf rules are nearly plain-language? pf r0x0rs!","tags":"misc","title":"Microsoft Security Awareness training"},{"url":"http://adamgetchell.org/enterprise-library-authentication.html","text":"Doug Rohrer , one of Avanade guys who worked on the Enterprise Library, has posted a fantastic End to End Enterprise Library project which incorporates the EL into ASP . NET and Winforms applications. Using Collin Collier's wonderful Copy Source As HTML makes blogging the code much easier. Looking at Doug's work, we run into the common pattern of writing a base page class which all asp.net pages inherit. Then he overrides the OnInit function to kickstart authentication. I've been using an ASP . NET Http Module to trap OnAuthenticate, but this is an interesting approach. Here's Dougs BasePage class: using System; using Microsoft.Practices.EnterpriseLibrary.Security; using SecCache = Microsoft.Practices.EnterpriseLibrary.Security.Cache; using Microsoft.Practices.EnterpriseLibrary.Configuration; using System.Web.Security; using System.Security.Principal; using EntLibCommonCSharp; namespace EntLibWebCSharp { /// \\ /// Summary description for BasePage. /// \\ public class BasePage: System.Web. UI .Page { \\#region Private Variables private IAuthenticationProvider \\_authenProvider; private IAuthorizationProvider \\_authorProvider; private IRolesProvider \\_rolesProvider; private ISecurityCacheProvider \\_secCacheProvider; private IPrincipal \\_principal; private EntLibCommonCSharp.AppConfigData \\_config; \\#endregion \\#region Public Properties /// \\ /// An Enterprize Library Authentication Provider instance. /// Used to determine if a user's credentials are valid. /// \\ internal IAuthenticationProvider AuthenProvider { get { if ( null ==\\_authenProvider) { \\_authenProvider = AuthenticationFactory.GetAuthenticationProvider(); } return \\_authenProvider; } } /// \\ /// An Enterprize Library Authorization Provider instance. /// Used to determine if a user is permitted to perform a certain action. /// \\ internal IAuthorizationProvider AuthorProvider { get { if ( null ==\\_authorProvider) { \\_authorProvider = AuthorizationFactory.GetAuthorizationProvider(); } return \\_authorProvider; } } /// \\ /// An Enterprize Library Roles Provider instance. /// Used to retrieve a principal object given an identity. /// \\ internal IRolesProvider RolesProvider { get { if ( null ==\\_rolesProvider) { \\_rolesProvider = RolesFactory.GetRolesProvider(); } return \\_rolesProvider; } } /// \\ /// An Enterprize Library Security Cache Provider instance. /// Used to store and retrieve a principal object given a security token. /// \\ internal ISecurityCacheProvider SecCacheProvider { get { if ( null ==\\_secCacheProvider) { \\_secCacheProvider = SecurityCacheFactory.GetSecurityCacheProvider(); } return \\_secCacheProvider; } } /// \\ /// The current principal /// \\ internal IPrincipal Principal { get { return \\_principal; } } /// \\ /// Provides easy access to configuration data in the application config file. /// \\ internal AppConfigData Config { get { if ( null ==\\_config) { \\_config = (AppConfigData)ConfigurationManager.GetConfiguration(AppConfigManager.SectionName); } return \\_config; } } /// \\ /// Sets the principal for this page request. /// \\ /// \\ The principal to use for the rest of the request. \\ internal void SetPrincipal(IPrincipal principal) { \\_principal = principal; } \\#endregion public BasePage() { // No constructor necessary } /// \\ /// Fires at the beginning of the page lifecycle. Overriden here to retrieve principal data from the /// Enterprise Library Security Cache provider or, if unable, to redirect to he login page. /// The Login.aspx page will add the appropriate token via the ASP . NET forms authentication cookie /// if the user successfully logs in. /// \\ /// \\ \\ protected override void OnInit(EventArgs e) { base .OnInit(e); // Make sure to skip this step if you're already on the login page if (ResolveUrl(\"\\~/Login.aspx\")!=Request.Url.AbsolutePath) { try { // Load the principal from the FormsAuthentication ticket information. FormsAuthenticationTicket ticket = FormsAuthentication.Decrypt(( string )Request.Cookies[FormsAuthentication.FormsCookieName].Value); GuidToken token = new GuidToken( new System.Guid(ticket.UserData)); IPrincipal principal = SecCacheProvider.GetPrincipal(token); if ( null ==principal) { Response.Redirect(\"\\~/Login.aspx\"); } else { SetPrincipal(principal); } } catch (Exception) { // If we have any issues, redirect to Login Response.Redirect(ResolveUrl(\"\\~/Login.aspx\")); } } } } } Cool stuff!","tags":"Programming","title":"Enterprise Library authentication"},{"url":"http://adamgetchell.org/fun-with-aspnet-security-and-windows.html","text":"Problem: you want secure database access, using a connection string like this: \\< add key =\"DatabaseConnection\" value =\"server= SERVER ;Persist Security Info=False;database= DATABASE ;Integrated Security= SSPI ;\"/\\> Solution: First, we're running IIS6 .0. So we can set up a separate Application Pool, and setup credentials for that application pool to use. We don't want to use Impersonation, because then our connection credentials will run as the application user, which may be different for each request, which will slow database access down because we won't be able to use database connection pooling. We don't want to use a domain account, because exploiting that account gives a free ride (and reconnaissance) to our entire network. We do want to use a local account, with minimal rights on the Windows 2003/ IIS6 .0 server. We can then duplicate that account on the SQL server, assign it appropriate rights to the databases we're using (and specifically, the stored procedures), and then use pass-through authentication. I used the ASPNET account (which will cause problems later, but they're interesting ones), though the account really doesn't matter (i.e. I did not use this account on our production server, but another one like it.) I think it's better to live dangerously on development boxes, to catch problems early. Of course, that's not all. In order for the account to be able to startup an application pool, it has to be a member of the IIS_WPG group. I didn't find that anywhere in MSDN or the KB articles, but by experimentation. So, pick an account, add it to the IIS_WPG group, create an application pool running under that account, duplicate that account on your SQL server, set permissions to the databases and stored procedures desired. Voila, right? Problem #2: You want to use the Enterprise Library Data Access Application Block. So following the guidelines you write some code like this: Database authDB = DatabaseFactory.CreateDatabase(\"Authentication\"); DBCommandWrapper dbCommandWrapper = authDB.GetStoredProcCommandWrapper(\"usp\\_LookupUserbyLoginID\"); dbCommandWrapper.AddInParameter(\"@kerbID\", System.Data.DbType.String, requestUserID); IDataReader reader = authDB.ExecuteReader(dbCommandWrapper); bool records = false ; But get an error like this: Security Exception Description: The application attempted to perform an operation not allowed by the security policy. To grant this application the required permission please contact your system administrator or change the application's trust level in the configuration file. Exception Details: System.Security.SecurityException: Requested registry access is not allowed. Source Error: +—————————————————————————————————————+ | Line 157: DBCommandWrapper dbCommandWrapper = authDB.GetStoredPro | | cCommandWrapper(\"usp_LookupUserbyLoginID\"); | | | | Line 158: dbCommandWrapper.AddInParameter(\"@kerbID\", System.Data. | | DbType.String, requestUserID); | | | | Line 159: IDataReader reader = authDB.ExecuteReader(dbCommandWrap | | per); | | | | Line 160: bool records = false; | | | | Line 161: | | | | | +—————————————————————————————————————+ Source File: \\Webdevel.caes.ucdavis.edu\\wwwroot\\$\\EligibilityList\\AuthenticationModule.cs Line: 159 Stack Trace: +—————————————————————————————————————+ | [SecurityException: Requested registry access is not allowed.] | | | | Microsoft.Win32.RegistryKey.OpenSubKey(String name, Boolean writa | | ble) +473 | | | | System.Diagnostics.EventLog.CreateEventSource(String source, Stri | | ng logName, String machineName, Boolean useMutex) +443 | | | | System.Diagnostics.EventLog.WriteEntry(String message, EventLogEn | | tryType type, Int32 eventID, Int16 category, Byte[] rawData) +347 | | | | System.Diagnostics.EventLog.WriteEntry(String message, EventLogEn | | tryType type, Int32 eventID, Int16 category) +21 | | | | System.Diagnostics.EventLog.WriteEntry(String message, EventLogEn | | tryType type, Int32 eventID) +15 | | | | Microsoft.Practices.EnterpriseLibrary.Common.Instrumentation.Even | | tLogger.Log(String message) | | | | | +—————————————————————————————————————+ If you look at the Stack Trace, you can see the problem is with the CreateEventSource() call. Even though you haven't specified using the Enterprise Library Logging Block, secretly it is still using System.Diagnostics.EventLog as part of its setup. Here's an article which describes the problem: PRB : \"Requested Registry Access Is Not Allowed\" Error Message When ASP . NET Application Tries to Write New EventSource in the EventLog Unfortunately, the solutions don't work. Solution #1, manually entering a registry key, didn't work for me. Solution #2, writing some code which calls CreateEventSource() also doesn't quite work either. I say quite because the issue is that CreateEventSource() needs to be called by a user with Administrative Rights. So what I did was create a project using my ErrorHandler class (from Fun with Microsoft's Enterprise Library ), setup the project to run in App Pool #1 which runs using the ASPNET account, grant that account Admin rights, do iisreset && gpupdate /force, open the project's default web form thereby causing an event to be written which calls the ErrorHandler class which calls CreateEventSource(), and then go back and revoke admin rights on ASPNET . Unfortunately, this needs to be done for every application which will call CreateEventSource() — unless you want to leave ASPNET running as Administrator ( very bad idea! ). Inelegant, but it works. I've notified Microsoft KB site of my findings; perhaps they'll revise the article, or show something more elegant. Update: This is also discussed in the Enterprise Library FAQ . However, the solutions given there are 1) run the \"Install Services\" script (why would you install Visual Studio on a server?) 2) use installutil on the EL assemblies (perhaps that will work — I'll have to try it) or 3) remove all logging from the EL (which in my case I want). Okay, we've got that problem taken care of. We write our EL application and breathlessly open the default page, only to find: Server Error in ‘/EligibilityList' Application. File or assembly name ko20f8cc.dll, or one of its dependencies, was not found. Description: An unhandled exception occurred during the execution of the current web request. Please review the stack trace for more information about the error and where it originated in the code. Exception Details: System. IO .FileNotFoundException: File or assembly name ko20f8cc.dll, or one of its dependencies, was not found. Source Error: Line 119: private bool Authorize(string requestUserID) Line 120: { Line 121: Database authDB = DatabaseFactory.CreateDatabase(\"Authentication\"); Line 122:// IDataReader dataReader; Line 123: DBCommandWrapper dbCommandWrapper = authDB.GetStoredProcCommandWrapper(\"usp_LookupUserbyLoginID\", new SqlParameter(\"@kerbID\", requestUserID)); This was discussed in the GotDotNet forums. The problem is this: Process and request identity in ASP . NET Behind the scenes the DAAB calls XmlSerializer, which want to write a temporary assembly to run. ASPNET (or the account you're running under) doesn't have access to the default temp directory, C:\\Windows\\temp, so the assembly can't be written and the DAAB halts. Nice. To fix this, give the account the Application Pool runs under Full (that's right, it needs to create subdirectories) permissions to C:\\Windows\\temp. By the way, this use of XmlSerializer has performance implications . Finally, Enterprise Library is installed, our code references it correctly, temporary assemblies can be written locally, life is good. Then we install Windows Server 2003 Service Pack 1. And instantly, our web pages return the very lonely: Service Unavailable Looking at IIS Manager, you can see that the Application Pool has been disabled. Looking in the System Log from Event Viewer shows this: A failure was encountered while launching the process serving application pool ‘AppPool #1'. The application pool has been disabled. For more information, see Help and Support Center at http://go.microsoft.com/fwlink/events.asp . Of course that link leads to no further information. To cut to the chase, the problem is that Windows Server 2003 SP1 has revoked rights/permissions on the ASPNET account, that cannot be restored even by placing it in the Administrators group. The way to fix the problem is: Go to the . NET Framework Folder (typically c:\\Windows\\Microsoft. NET \\Framework\\v1.1.4322) aspnet_regiis -ua to uninstall the framework aspnet_regiis -i to reinstall the framework In IIS Manager: Enable ASP . NET pages In User manager (compmgmt.msc) Set the ASPNET account with the password on the SQL server, and as a member of IIS_WPG In IIS Manager: Set the Application pool to run under the account with the password entered from the previous step At the Run command: iisreset to reset IIS gpupdate /force to ensure password synchronization Wasn't that fun? Thank goodness Whidbey and Enterprise Library v2.0 aren't coming out until September.","tags":"Programming","title":"Fun with ASP . NET security and Windows 2003 SP1 breakage"},{"url":"http://adamgetchell.org/using-enterprise-library-logging.html","text":"To get logging working without pesky WMI /Performance counter errors on every logged event: Per Tom Hollander's weblog Go to the Logging project, Project Properties dialog for the Common project, and under Configuration Properties\\Build, find the Conditional Compilation Properties property and remove ; USEWMI ; USEPERFORMANCECOUNTER for the build type you're interested in (ReleaseFinal, in this case). Ignore compile warnings about DB2 goop. Delete any old project references and re-add reference to new version in C:\\Program Files\\Microsoft Enterprise Library\\src\\Logging\\bin\\ReleaseFinal. Then add an appropriate using statement and use in code: using System; using System.Collections; using System.ComponentModel; using System.Data; using System.Drawing; using System.Web; using System.Web.SessionState; using System.Web. UI ; using System.Web. UI .WebControls; using System.Web. UI .HtmlControls; using Microsoft.Practices.EnterpriseLibrary.Logging; using Microsoft.Practices.EnterpriseLibrary.Logging.Tracing; namespace CAESDO { /// \\ /// Summary description for WebForm1. /// \\ public class DefaultPage : System.Web. UI .Page { private void Page\\_Load( object sender, System.EventArgs e) { // Put user code to initialize the page here LogEntry logEntry = new LogEntry(); logEntry.Message = \"Starting up the application\"; Logger.Write(logEntry); // Now this is cool! Tracing flow of code through application // and it was simple to add an EmailAlert with an EmailSink using ( new Tracer(\"Trace\")) { Logger.Write(\"Hello world\"); Logger.Write(\"Hello by e-mail\", \"EmailAlerts\",5,3000,Microsoft.Practices.EnterpriseLibrary.Logging.Severity.Information, \"An e-mail message logging all kinds of stuff\"); } } \\#region Web Form Designer generated code override protected void OnInit(EventArgs e) { // // CODEGEN : This call is required by the ASP . NET Web Form Designer. // InitializeComponent(); base .OnInit(e); } /// \\ /// Required method for Designer support - do not modify /// the contents of this method with the code editor. /// \\ private void InitializeComponent() { this .Load += new System.EventHandler( this .Page\\_Load); } \\#endregion } } Voila! It'd sure make it easier to post code to my weblog if VisualStudio 2005 included CopySourceAsHtml functionality. This is a great application, too bad it doesn't work for me. I seem to have uncovered the first interaction between CSAH and a trial VisualPerl installation that won't uninstall. Par for the course. Although, I've suggested to the Visual Studio 2005 guys that they add this feature. P.S. Collin worked to fix CSAH , and I nuked and reinstalled my system, including Visual Studio 2003. NET . That seems to have done the trick.","tags":"Programming","title":"Using Enterprise Library Logging"},{"url":"http://adamgetchell.org/beginning-string-theory.html","text":"Okay, I've been posting enough about my day job. By night I'm a physics graduate student. Well, my work lets me go to class during the day, but (when I'm productive) night and weekend minutes are for physics (sounds like a mobile phone commercial). I'm currently tackling String Theory — we finally have a graduate course at UCD after my petition to start one last year. Great stuff! The whole reason I wanted to study physics to begin with. It's being taught by Professor John March-Russell, visiting us from Oxford. Some great material on Philosophy of Physics by Oliver Pooley : I found it while reviewing general covariance. Of particular relevance is his lecture on General Covariance and gauge theories , which helped to clarify the muddled thoughts I had running in my head. Paul Ginsparg's review of Applied Conformal Field Theory posted on his brain-child, arxiv.org . Necessary material since I learned the deep-connections between Conformal Field Theory in 2d and string theory are what tell us so much about 2d objects like strings propagating along a world-sheet. Belavin, Polyakov, and Zamolodchikov's classic article \" INFINITE CONFORMAL SYMMETRY IN TWO - DIMENSIONAL QUANTUM FIELD THEORY \" unfortunately isn't on arxiv, and right now our electronic journals aren't responding, so I may have to track down Nucl.Phys.B241:333–380,1984 on actual paper. Well, this was fun but I should go back to reviewing my notes.","tags":"Physics","title":"Beginning String Theory"},{"url":"http://adamgetchell.org/signing-and-installing.html","text":"If you want to know how to do this, the gory details are here .","tags":"Programming","title":"Signing and Installing the EnterpriseLibrary in the GAC"}]}